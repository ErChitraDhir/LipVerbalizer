{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ErChitraDhir/demo-repo/blob/main/Lip_Verbalizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy_pDaHaPdiU"
      },
      "source": [
        "0. Install and import Dependencies:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuDTiqWjP-UL"
      },
      "outputs": [],
      "source": [
        "!pip list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9N512bPnO9NB"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python matplotlib imageio gdown tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2Dkr0rqVFVs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from typing import List\n",
        "from matplotlib import pyplot as plt\n",
        "import imageio\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UlCoXLwXpd-"
      },
      "outputs": [],
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AE80Za7Y34Q"
      },
      "outputs": [],
      "source": [
        "physical_devices=tf.config.list_physical_devices('GPU')\n",
        "try:\n",
        "  tf.config.experimental.set_memory_growth(physical_devices[0],True)\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2GAeSKRZZcS"
      },
      "source": [
        "1. Build data loading functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTcWNa1kZdnc"
      },
      "outputs": [],
      "source": [
        "import gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BsR4lYDlbUT7"
      },
      "outputs": [],
      "source": [
        "url='https://drive.google.com/uc?id=1YlvpDLix3S-U8fd-gqRwPcWXAXm8JwjL'\n",
        "output='data.zip'\n",
        "gdown.download(url,output,quiet=False)\n",
        "gdown.extractall('data.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFwoSVmEb_eH"
      },
      "outputs": [],
      "source": [
        "def load_video(path:str)-> List[float]:\n",
        "\n",
        "  cap=cv2.VideoCapture(path)\n",
        "  frames=[]\n",
        "  for _ in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
        "    ret,frame=cap.read()\n",
        "    frame=tf.image.rgb_to_grayscale(frame)\n",
        "    frames.append(frame[190:236,80:220,:])\n",
        "  cap.release()\n",
        "\n",
        "  mean=tf.math.reduce_mean(frames)\n",
        "  std=tf.math.reduce_std(tf.cast(frames,tf.float32))\n",
        "  return tf.cast((frames-mean),tf.float32)/ std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioK2G9zws2yp"
      },
      "outputs": [],
      "source": [
        "vocab = [x for x in \"abcdefghijklmnopqrstuvwxyz'?!123456789 \"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Y0wYnoMtRT4"
      },
      "outputs": [],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTFW5RQqtUKN"
      },
      "outputs": [],
      "source": [
        "char_to_num = tf.keras.layers.StringLookup(vocabulary=vocab,oov_token=\"\")\n",
        "num_to_char =tf.keras.layers.StringLookup(vocabulary=char_to_num.get_vocabulary(),oov_token=\"\", invert=True)\n",
        "\n",
        "print(f\"the vocabulary is:{char_to_num.get_vocabulary()}\"\n",
        "      f\"(size ={char_to_num.vocabulary_size()})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBjXFwBqy3ls"
      },
      "outputs": [],
      "source": [
        "char_to_num.get_vocabulary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Zy9QNz-uLj7"
      },
      "outputs": [],
      "source": [
        "char_to_num(['a','b','c'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qr6VXBYEvd7A"
      },
      "outputs": [],
      "source": [
        "num_to_char([1,2,3,4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWixnuZ55LqX"
      },
      "outputs": [],
      "source": [
        "def load_alignments(path:str) -> List[str]:\n",
        "    with open(path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    tokens = []\n",
        "    for line in lines:\n",
        "        line = line.split()\n",
        "        if line[2] != 'sil':\n",
        "            tokens = [*tokens,' ',line[2]]\n",
        "    return char_to_num(tf.reshape(tf.strings.unicode_split(tokens, input_encoding='UTF-8'), (-1)))[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXvx3RKU0XTe"
      },
      "outputs": [],
      "source": [
        "def load_data(path: str):\n",
        "    path = bytes.decode(path.numpy())\n",
        "    file_name = path.split('/')[-1].split('.')[0]\n",
        "    # File name splitting for windows\n",
        "    #file_name = path.split('\\\\')[-1].split('.')[0]\n",
        "    video_path = os.path.join('data','s1',f'{file_name}.mpg')\n",
        "    alignment_path = os.path.join('data','alignments','s1',f'{file_name}.align')\n",
        "    frames = load_video(video_path)\n",
        "    alignments = load_alignments(alignment_path)\n",
        "\n",
        "    return frames, alignments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRhIYcGy1mei"
      },
      "outputs": [],
      "source": [
        "test_path='./data/s1/bbaf2n.mpg'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rWw6mWm_HRY"
      },
      "outputs": [],
      "source": [
        "tf.convert_to_tensor(test_path).numpy().decode('utf-8').split('/')[-1].split('.')[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59SYKX4o_L6w"
      },
      "outputs": [],
      "source": [
        "frames,alignments=load_data(tf.convert_to_tensor(test_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WudpHiXfHQa8"
      },
      "outputs": [],
      "source": [
        "plt.imshow(frames[50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBoODCl9BXBC"
      },
      "outputs": [],
      "source": [
        "alignments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taete4QRCeE1"
      },
      "outputs": [],
      "source": [
        "print(tf.strings.reduce_join([bytes.decode(x) for x in num_to_char(alignments.numpy()).numpy()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqzHYieJHt-i"
      },
      "outputs": [],
      "source": [
        "print(tf.strings.reduce_join([bytes.decode(x) for x in num_to_char(alignments.numpy()).numpy()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7jnjPLDKML6"
      },
      "outputs": [],
      "source": [
        "def mappable_function(path:str)-> List[str]:\n",
        "  result=tf.py_function(load_data,[path],(tf.float32,tf.int64))\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ODrfsLkmHUP"
      },
      "source": [
        "2. Create Data Pipeline:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQpi6hRLmNgQ"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAuyCkEundwB"
      },
      "outputs": [],
      "source": [
        "data=tf.data.Dataset.list_files('./data/s1/*.mpg')\n",
        "data=data.shuffle(500,reshuffle_each_iteration=False)\n",
        "data=data.map(mappable_function)\n",
        "data=data.padded_batch(2,padded_shapes=([75,None,None,None],[40]))\n",
        "data=data.prefetch(tf.data.AUTOTUNE)\n",
        "train=data.take(450)\n",
        "test=data.skip(450)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2d8rD-0eZd7"
      },
      "outputs": [],
      "source": [
        "len(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Rpa_mAVn9MM"
      },
      "outputs": [],
      "source": [
        "frames,alignments = data.as_numpy_iterator().next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IP6z2UKoWAJ"
      },
      "outputs": [],
      "source": [
        "frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNaHU23powpK"
      },
      "outputs": [],
      "source": [
        "alignments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHNTDJscozEn"
      },
      "outputs": [],
      "source": [
        "#plt.imshow(frames[0])\n",
        "len(frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHvxv7euqRE9"
      },
      "outputs": [],
      "source": [
        "test=data.as_numpy_iterator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-alp1lHZqcjF"
      },
      "outputs": [],
      "source": [
        "val=test.next();val[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjyaXyZocYtG"
      },
      "outputs": [],
      "source": [
        "imageio.mimsave"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwRqpCy_GSUM"
      },
      "outputs": [],
      "source": [
        "plt.imshow(val[0][0][35])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QCDH_4ltoMg"
      },
      "outputs": [],
      "source": [
        "tf.strings.reduce_join([num_to_char(word) for word in val[1][0]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgOp37VjPAqY"
      },
      "source": [
        "3. Design the Deep Neural Network:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qnHgq6_PF-T"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv3D, LSTM, Dense, Dropout, Bidirectional, MaxPool3D, Activation, Reshape, SpatialDropout3D, BatchNormalization, TimeDistributed, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRuObl12Qqol"
      },
      "outputs": [],
      "source": [
        "data.as_numpy_iterator().next()[0][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6xjyWQaRlCG"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv3D(128, 3, input_shape=(75,46,140,1), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool3D((1,2,2)))\n",
        "\n",
        "model.add(Conv3D(256, 3, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool3D((1,2,2)))\n",
        "\n",
        "model.add(Conv3D(75, 3, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool3D((1,2,2)))\n",
        "\n",
        "model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
        "model.add(Dropout(.5))\n",
        "\n",
        "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
        "model.add(Dropout(.5))\n",
        "\n",
        "model.add(Dense(char_to_num.vocabulary_size()+1, kernel_initializer='he_normal', activation='softmax'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpdWchieS0K-"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAAsbwvyS4k4"
      },
      "outputs": [],
      "source": [
        "yhat=model.predict(val[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dyLOuC4URW4"
      },
      "outputs": [],
      "source": [
        "tf.argmax(yhat[0],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpLkb8BPT6nJ"
      },
      "outputs": [],
      "source": [
        "tf.strings.reduce_join([num_to_char(x) for x in tf.argmax(yhat[0],axis=1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKIQFi2SUnXT"
      },
      "outputs": [],
      "source": [
        "model.input_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXx0dINwUx8W"
      },
      "outputs": [],
      "source": [
        "model.output_shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPsPpvpjVRXW"
      },
      "source": [
        "4.Setup training options and train:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ft-xK9DGU2Kc"
      },
      "outputs": [],
      "source": [
        "def scheduler(epoch, lr):\n",
        "    if epoch < 30:\n",
        "        return lr\n",
        "    else:\n",
        "        return lr * tf.math.exp(-0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yX7QQ3PgWEhz"
      },
      "outputs": [],
      "source": [
        "def CTCLoss(y_true, y_pred):\n",
        "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
        "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
        "\n",
        "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "\n",
        "    loss = tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmPfc0RMWi-_"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class ProduceExample(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, dataset) -> None:\n",
        "        self.dataset = dataset.as_numpy_iterator()\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None) -> None:\n",
        "        data = self.dataset.next()\n",
        "        yhat = self.model.predict(data[0])\n",
        "        decoded = tf.keras.backend.ctc_decode(yhat, [75,75], greedy=False)[0][0].numpy()\n",
        "        for x in range(len(yhat)):\n",
        "            print('Original:', tf.strings.reduce_join(num_to_char(data[1][x])).numpy().decode('utf-8'))\n",
        "            print('Prediction:', tf.strings.reduce_join(num_to_char(decoded[x])).numpy().decode('utf-8'))\n",
        "            print('~'*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcNfXGxMXGSc"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss=CTCLoss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7X0W1BVXQoj"
      },
      "outputs": [],
      "source": [
        "checkpoint_callback = ModelCheckpoint(os.path.join('models','checkpoint'), monitor='loss', save_weights_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDuBRTH1cv39"
      },
      "outputs": [],
      "source": [
        "schedule_callback = LearningRateScheduler(scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M55XHz-XcwAL"
      },
      "outputs": [],
      "source": [
        "example_callback = ProduceExample(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fv4L4nefeX2",
        "outputId": "b5fad3cd-2bb6-4cc8-cc89-f7f264233f1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            " 39/450 [=>............................] - ETA: 6:48:07 - loss: 120.5684"
          ]
        }
      ],
      "source": [
        "model.fit(train, validation_data=test, epochs=100, callbacks=[checkpoint_callback, schedule_callback, example_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUjPBLTvgtvi"
      },
      "source": [
        "5.Make Predictions and Test Time:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58XB24vdgyh_"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "url = 'https://drive.google.com/uc?id=1vWscXs4Vt0a_1IH1-ct2TCgXAZT-N3_Y'\n",
        "output = 'checkpoints.zip'\n",
        "gdown.download(url, output, quiet=False)\n",
        "gdown.extractall('checkpoints.zip', 'models')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlU-q2Tlh_xE"
      },
      "outputs": [],
      "source": [
        "model.load_weights('models/checkpoint')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0F9n1GqXxq1X"
      },
      "outputs": [],
      "source": [
        "test_data = test.as_numpy_iterator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbHyLkCtxtGV"
      },
      "outputs": [],
      "source": [
        "sample = test_data.next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImyDFmAsxuxq"
      },
      "outputs": [],
      "source": [
        "hat = model.predict(sample[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQmZrLQoxwkc"
      },
      "outputs": [],
      "source": [
        "print('~'*100, 'REAL TEXT')\n",
        "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in sample[1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAV1xrPpxyCa"
      },
      "outputs": [],
      "source": [
        "decoded = tf.keras.backend.ctc_decode(yhat, input_length=[75,75], greedy=True)[0][0].numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmWw95TRx02x"
      },
      "outputs": [],
      "source": [
        "print('~'*100, 'PREDICTIONS')\n",
        "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vCYf01Tx9Rc"
      },
      "source": [
        "Test on a Video:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0BJw4CUyCu6"
      },
      "outputs": [],
      "source": [
        "sample = load_data(tf.convert_to_tensor('.\\\\data\\\\s1\\\\bras9a.mpg'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqza-KxjyFmx"
      },
      "outputs": [],
      "source": [
        "print('~'*100, 'REAL TEXT')\n",
        "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in [sample[1]]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvEDXXP_yHwI"
      },
      "outputs": [],
      "source": [
        "yhat = model.predict(tf.expand_dims(sample[0], axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmZ9U5EVyJ8H"
      },
      "outputs": [],
      "source": [
        "decoded = tf.keras.backend.ctc_decode(yhat, input_length=[75], greedy=True)[0][0].numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDNbNKK4yML5"
      },
      "outputs": [],
      "source": [
        "print('~'*100, 'PREDICTIONS')\n",
        "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2CGYdq0yO0v"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "14pfR61BfX92kYCna6yciCHILodQbPHuX",
      "authorship_tag": "ABX9TyMeml8elDvymh+NZVeVrcjm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}